<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>math on Is this Math?</title>
    <link>/tags/math/</link>
    <description>Recent content in math on Is this Math?</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/math/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tangent vectors as derivations (Manifolds by Tu)</title>
      <link>/2020/09/22/tangent-vectors-as-derivations-manifolds-by-tu/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/22/tangent-vectors-as-derivations-manifolds-by-tu/</guid>
      <description>(\require{physics})
Notes on an Introduction to Manifolds (by Tu) Some extremely wordy notes based on An Introduction to Manifolds by Loring W. Tu, mainly to clarify some basis things to myself.
A key concept is coordinate-free objects. In this case, how do we define tangent vectors in a coordinate free way? (But also why do we even care?)
Tangent vectors in $\mathbb{R}$ as Derivations The book starts with defining tangent vectors to a curve (in $\mathbb{R}^3$) at point $p$.</description>
    </item>
    
    <item>
      <title>Transforming the data of a likelihood involves a Jacobian; why the likelihood ratio is the key object</title>
      <link>/2020/07/27/transforming-the-data-of-a-likelihood-involves-a-jacobian/</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/27/transforming-the-data-of-a-likelihood-involves-a-jacobian/</guid>
      <description>The likelihood ratio is the primary object of interest because if we transform the data \(X\) to \(Y\), our information about a fixed parameter \(\theta\) should not change. This mathematically follows from calculus.
Transforming the data (random variable) of a likelihood involves a Jacobian term\[L(\theta; y) = L(\theta; x)\left| \frac{\partial x}{\partial y}\right|\]
The [[Classical definition of the likelihood]] starts with a statistical model and thus a probability density \(p_\theta(x)\).</description>
    </item>
    
    <item>
      <title>Calculating the determinent of an equicovariance matrix</title>
      <link>/2020/06/30/calculating-the-determinent-of-an-equicovariance-matrix/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/06/30/calculating-the-determinent-of-an-equicovariance-matrix/</guid>
      <description>The goal is to find the determinant by re-writing \(\Sigma\) as a upper triangular matrix. Then [[Determinant of triangular matrix is the product of the diagonal]]
We add a new row and new column. Recall that the determinant can be defined recursively. Since the new matrix has a \(1\) in the \(\Sigma_{11}\) position, then the determinant remains the same.We aim to eliminate the original off diagonals. We need to remove the lower diagonal for obvious reasons.</description>
    </item>
    
  </channel>
</rss>