<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>math on A blog by Stone</title>
    <link>/categories/math/</link>
    <description>Recent content in math on A blog by Stone</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jul 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/math/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A higher level examination of M-estimator consistency proof</title>
      <link>/2020/07/10/a-higher-level-examination-of-m-estimator-consistency-proof/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/10/a-higher-level-examination-of-m-estimator-consistency-proof/</guid>
      <description>The proof of the [[Consistency of M-Estimators (uniform convergence)]] has two major parts:
converging the “\(y\)” values: by squeezing \(M(\theta_0)\) in between \(M(\hat{\theta}_n)\) and \(M_n(\hat{\theta}_n)\)“\(y\)” values only get close near \(\theta_0\): well separated says that the only place where \(M\) is nearConverging the \(y\) valuesI was originally imagining the first part of the proof using a full \(M(\cdot)\) by \(\theta\) graph but it might be easier to just imagine it as a straight line.</description>
    </item>
    
    <item>
      <title>Walking through the delta method</title>
      <link>/2020/07/06/walking-through-the-delta-method/</link>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/06/walking-through-the-delta-method/</guid>
      <description>Imagine we’ve constructed an estimator \(T_n\) for some parameter \(\theta\) but what we really want to know about is \(\phi(\theta)\), some transformation of the parameter.
Can we use our knowledge of the behavior of \(T_n\) to learn about \(\phi(T_n)\)?
By the continuous-mapping theorem if \(\phi\) is continuous then:
if \(T_n \to \theta\)then \(\phi(T_n) \to \phi(\theta)\)By the delta method we have
if \(\sqrt{n}(T_n - \theta) \rightsquigarrow T\) as \(n \to \infty\)then \(\sqrt{n}(\phi(T_n) - \phi(\theta)) \rightsquigarrow \phi&amp;#39;_\theta(T)\)where \(\phi&amp;#39;_\theta(T) = \phi&amp;#39;(\theta)*T\).</description>
    </item>
    
    <item>
      <title>O notation depends on what limit you&#39;re taking</title>
      <link>/2020/07/02/o-notation-depends-on-what-limit-you-re-taking/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/02/o-notation-depends-on-what-limit-you-re-taking/</guid>
      <description>Something that confused me about \(O\) notation was that it appeared to take different meaning between algorithms and calculus. This was resolved by seeing that the notation provides a convenient way of describing the limit of a function \(f(x)\) as \(x\) approaches a specific limit. This point about the \(O\)-ness of a function being contingent on what limit you were taking was the crux of my confusion.
This limit is typically different between a standard algorithms and calculus course.</description>
    </item>
    
  </channel>
</rss>